{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [],
   "source": [
    "path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(include_top = False,\n",
    "                                input_shape = (150, 150, 3),\n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "  # Your Code Here\n",
    "    layer.trainable = False\n",
    "  \n",
    "# Print the model summary\n",
    "# pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc')>0.97):\n",
    "            print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation = 'relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation = 'sigmoid')(x)           \n",
    "model = Model(pre_trained_model.input, outputs = x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = os.path.join(train_dir, 'horses')\n",
    "train_humans_dir = os.path.join(train_dir, 'humans')\n",
    "validation_horses_dir = os.path.join(validation_dir, 'horses')\n",
    "validation_humans_dir = os.path.join(validation_dir, 'humans')\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)\n",
    "train_humans_fnames = os.listdir(train_humans_dir)\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1/255,\n",
    "                                  height_shift_range = 0.2,\n",
    "                                  width_shift_range = 0.2,\n",
    "                                  horizontal_flip = True,\n",
    "                                  vertical_flip = True,\n",
    "                                  rotation_range = 0.4,\n",
    "                                  shear_range = 0.1,\n",
    "                                  zoom_range = 0.3,\n",
    "                                  fill_mode = 'nearest'\n",
    "                                  )\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size = (150, 150),\n",
    "                                                   batch_size = 20,\n",
    "                                                   class_mode = 'binary',\n",
    "                                                   shuffle = True)     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                        target_size = (150, 150),\n",
    "                                                        batch_size =20,\n",
    "                                                        class_mode = 'binary',\n",
    "                                                        shuffle = False)\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "52/52 [==============================] - 48s 925ms/step - loss: 0.2925 - acc: 0.8851 - val_loss: 0.0075 - val_acc: 0.9961\n",
      "Epoch 2/3\n",
      "52/52 [==============================] - 39s 758ms/step - loss: 0.1440 - acc: 0.9445 - val_loss: 0.0139 - val_acc: 0.9961\n",
      "Epoch 3/3\n",
      "52/52 [==============================] - 39s 758ms/step - loss: 0.1274 - acc: 0.9494 - val_loss: 0.0255 - val_acc: 0.9922\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit_generator(train_generator,\n",
    "                              epochs = 3,\n",
    "                              validation_data = validation_generator,\n",
    "                              verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.session.delete();\n",
    "window.onbeforeunload = null\n",
    "setTimeout(function() { window.close(); }, 1000);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
